import burlap.behavior.singleagent.planning.stochastic.policyiteration.PolicyIteration;
import burlap.behavior.singleagent.planning.stochastic.valueiteration.ValueIteration;
import burlap.domain.singleagent.graphdefined.GraphDefinedDomain;
import burlap.oomdp.auxiliary.DomainGenerator;
import burlap.oomdp.auxiliary.common.NullTermination;
import burlap.oomdp.core.*;
import burlap.oomdp.core.states.State;
import burlap.oomdp.singleagent.GroundedAction;
import burlap.oomdp.singleagent.RewardFunction;
import burlap.oomdp.statehashing.DiscretizingHashableStateFactory;


public class RewardShapingHW5TestEg1 {
		
    DomainGenerator				dg;
    Domain						domain;
    State						initState;
    RewardFunction				rf;
    RewardFunction              rf1;
    TerminalFunction			tf;
    DiscretizingHashableStateFactory	hashFactory;
    int numStates; 
    
    
    double finalval[];
    double [][][] transitionProb;
    
    
    public RewardShapingHW5TestEg1(double[][][] probabilitiesOfTransitions,
    		                double[][][] rewards ,double gamma,int numStates, int numActions) {
        this.numStates = numStates;
        this.dg = new GraphDefinedDomain(numStates);
        this.finalval = new double[numStates];
        
       
         //double totalVal;
         for(int i = 0; i < numStates;i++){
        	
        	for(int j = 0; j < numActions;j++){
        		for(int k = 0; k < numStates;k++){
        			
        			
        			 ((GraphDefinedDomain) this.dg).setTransition(i, j, k, 
        					 probabilitiesOfTransitions[i][j][k]);
        		
        		}
        		}
           }
        
       
        this.domain = this.dg.generateDomain();
        
        this.initState = GraphDefinedDomain.getState(this.domain,1);
      
        this.rf = new SimpleRF(rewards);
        
        //int terminalStates[] = {0,3,6,7};
        
        //this.tf = new ManyStateTF(terminalStates);
        
        this.tf = new NullTermination();
        
        this.transitionProb = probabilitiesOfTransitions;
        
        this.hashFactory = new DiscretizingHashableStateFactory(0);
   
        
    }
    
    
    
    private void setRewardFun(double [][][]rewards, double gamma, int numStates,
    		double [][][] transitionProb){
    	
    	double finVal[] = FuncValue(numStates);
    	
    	this.rf1 = new RewardShapingRF(rewards,gamma,finVal,transitionProb);
    	
    	 }

    

    public static class SimpleRF implements RewardFunction {
		
    	double[][][] rewards;
    	
		public SimpleRF(double[][][] rewards) {
			this.rewards = rewards;
			
		}
		
		@Override
		public double reward(State s, GroundedAction a, State sprime) {
			
			int sid = GraphDefinedDomain.getNodeId(s);
			int targetid = GraphDefinedDomain.getNodeId(sprime);
			String actionName = a.actionName();
			int actionId = Integer.parseInt(actionName.substring(6,7));
			
			double r;
			r = rewards[sid][actionId][targetid];
			return r;
		}
    }




public static class ManyStateTF implements TerminalFunction{
	   
	int[] stateId;
	public ManyStateTF(int [] stateId){
		this.stateId = stateId;
		
	}
	
	
	@Override
	public boolean isTerminal(State s) {
		
		boolean isTerminal = false;
		
		int sid = GraphDefinedDomain.getNodeId(s);
		for(int i = 0; i < stateId.length;i++){
			if(sid == stateId[i]){
				isTerminal = true;
			}
		}
		
		return isTerminal;
	  }
	}


  
    
private ValueIteration computeValue(double gamma ,State s) {
   	double maxDelta = 0.0001;
   	int maxIterations = 1000;
   	ValueIteration vi = new ValueIteration(this.domain, this.rf, this.tf, gamma, 
   			this.hashFactory, maxDelta, maxIterations);
   	vi.planFromState(s);
     return vi;
      }
    
    
     private double[] FuncValue(int numStates){
    	 
    	State state1 = GraphDefinedDomain.getState(this.domain,1);
    	 
        double finVal1[] = new double[numStates];
        
        ValueIteration vi = computeValue(0.999,state1);
        
        for(int i = 0; i < numStates;i++){
        
        State state = GraphDefinedDomain.getState(this.domain,i);
        
        finVal1[i] = vi.value(state); 
        
       }
        
        for(int i = 0; i < numStates;i++){
        	
        	System.out.println(finVal1[i]);
        }
    	 return finVal1;
    	
     }
    




public static class RewardShapingRF implements RewardFunction {
		
    	double[][][] rewards;
    	double gamma;
    	double [][][] transitionProb;
    	
    	double finalval[];
		
		public RewardShapingRF(double[][][] rewards,double gamma,
				                double finalval[], double[][][] transitionProb ) {
			this.rewards = rewards;
			this.gamma = gamma;
			this.transitionProb = transitionProb;
			
			this.finalval = finalval;
		}
		
		
		public double psiFunc( double valueOfState,double gamma){
			
			double val = gamma *valueOfState; 
			return val;
		}
		
		
		@Override
		public double reward(State s, GroundedAction a, State sprime) {
			
			int sid = GraphDefinedDomain.getNodeId(s);
			int targetid = GraphDefinedDomain.getNodeId(sprime);
			String actionName = a.actionName();
			int actionId = Integer.parseInt(actionName.substring(6,7));
			
			double r = 0.0;
			
			double finalReward = 0.0;;
			
			double shapeVal = 0.0;
			
			
			
			r = rewards[sid][actionId][targetid];
			
			double psiTargetState = finalval[targetid];
			
			double psiOrigState = finalval[sid];
			
			shapeVal = gamma* psiTargetState  - psiOrigState ;
		   
			finalReward = r   + shapeVal;
			
			
		   return finalReward ;
		 }
    }
    
    
   
   public void PolicyIterationRFModified(double gamma1){
		 
		 double gamma = gamma1;
		 double maxDelta = 0.0001;
		 int maxEvaluationIterations = 100;
		 int maxPolicyIterations = 100;
		 State state1 = GraphDefinedDomain.getState(this.domain,1);
		 
		 PolicyIteration obj = new PolicyIteration(this.domain, 
				 this.rf1,this.tf,gamma,this.hashFactory, maxDelta, 
				maxEvaluationIterations, maxPolicyIterations);
		 
		
		  obj.planFromState(state1);
		 
		  int totalPolIteration = obj.getTotalPolicyIterations();
		 System.out.println("total policy iteration " + totalPolIteration);
		 
		 
		  }
    
    public void PolicyIterationRFSimple(double gamma1){
		 
		 double gamma = gamma1;
		 double maxDelta = 0.0001;
		 int maxEvaluationIterations = 100;
		 int maxPolicyIterations = 100;
		 State state1 = GraphDefinedDomain.getState(this.domain,1);
		 
		 PolicyIteration obj = new PolicyIteration(this.domain, 
				 this.rf,this.tf,gamma,this.hashFactory, maxDelta, 
				maxEvaluationIterations, maxPolicyIterations);
		 
		
		  obj.planFromState(state1);
		 
		  int totalPolIteration = obj.getTotalPolicyIterations();
		 System.out.println("total policy iteration " + totalPolIteration);
		 
		 
		  }
   
    
     
   public static void main(String[] args) {
		
		//Test example 1
		
	    double[][][] probabilitiesOfTransitions = {{{1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0}},{{0.0,0.9,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.1,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.8,0.1,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.1,0.1,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0}},{{0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0}},{{0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0}},{{0.0,0.1,0.0,0.0,0.0,0.8,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.8,0.0,0.0,0.1,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.1,0.0,0.0,0.8,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.1,0.1,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0}},{{0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0}},{{0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0}},{{0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.8,0.0,0.0,0.1,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.8,0.0,0.1,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.1,0.0,0.8,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.1,0.0,0.0,0.8,0.0,0.0,0.0,0.0}},{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0}},{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0}},{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.8,0.0,0.1,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.1,0.1,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.8,0.0,0.0,0.1,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.1,0.0,0.8,0.0}},{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0}},{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0}},{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0}},{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0}}};
		double[][][] rewards = {{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0}},{{-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-0.1,1.0,-0.1},{-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-0.1,1.0,-0.1},{-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-0.1,1.0,-0.1},{-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-0.1,1.0,-0.1}},{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0}},{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0}},{{-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-0.1,1.0,-0.1},{-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-0.1,1.0,-0.1},{-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-0.1,1.0,-0.1},{-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-0.1,1.0,-0.1}},{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0}},{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0}},{{-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-0.1,1.0,-0.1},{-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-0.1,1.0,-0.1},{-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-0.1,1.0,-0.1},{-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-0.1,1.0,-0.1}},{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0}},{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0}},{{-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-0.1,1.0,-0.1},{-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-0.1,1.0,-0.1},{-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-0.1,1.0,-0.1},{-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-1.0,-0.1,-0.1,-0.1,-0.1,-1.0,-0.1,1.0,-0.1}},{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0}},{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0}},{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0}},{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0}}};;
		double gamma = 0.99;
		int numStates = 15;
		int numActions = 4;
	
		//Test example 2
		
		
		/*int numStates = 12;
		int numActions = 4;
		double[][][] probabilitiesOfTransitions = {{{1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0}},{{0.0,0.1,0.8,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.9,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.9,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.1,0.1,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0}},{{0.0,0.0,0.9,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0},{0.0,0.1,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.8,0.1,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0},{0.0,0.1,0.1,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0}},{{0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0}},{{0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0}},{{0.0,0.1,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.1,0.0,0.0},{0.0,0.8,0.0,0.0,0.1,0.0,0.1,0.0,0.0,0.0,0.0,0.0},{0.0,0.1,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.1,0.0,0.0},{0.0,0.0,0.0,0.0,0.1,0.0,0.1,0.0,0.0,0.8,0.0,0.0}},{{0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.1,0.0},{0.0,0.0,0.8,0.0,0.0,0.1,0.0,0.1,0.0,0.0,0.0,0.0},{0.0,0.0,0.1,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.1,0.0},{0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.1,0.0,0.0,0.8,0.0}},{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0}},{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0}},{{0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.1,0.8,0.0},{0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.1,0.1,0.0},{0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.9,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.1,0.0}},{{0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.9,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.1,0.1,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.8,0.1,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.9,0.0}},{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0}}};
		double[][][] rewards = {{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0}},{{-0.1,-0.1,-0.1,-0.1,1.0,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,-0.1},{-0.1,-0.1,-0.1,-0.1,1.0,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,-0.1},{-0.1,-0.1,-0.1,-0.1,1.0,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,-0.1},{-0.1,-0.1,-0.1,-0.1,1.0,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,-0.1}},{{-0.1,-0.1,-0.1,-0.1,1.0,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,-0.1},{-0.1,-0.1,-0.1,-0.1,1.0,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,-0.1},{-0.1,-0.1,-0.1,-0.1,1.0,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,-0.1},{-0.1,-0.1,-0.1,-0.1,1.0,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,-0.1}},{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0}},{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0}},{{-0.1,-0.1,-0.1,-0.1,1.0,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,-0.1},{-0.1,-0.1,-0.1,-0.1,1.0,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,-0.1},{-0.1,-0.1,-0.1,-0.1,1.0,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,-0.1},{-0.1,-0.1,-0.1,-0.1,1.0,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,-0.1}},{{-0.1,-0.1,-0.1,-0.1,1.0,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,-0.1},{-0.1,-0.1,-0.1,-0.1,1.0,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,-0.1},{-0.1,-0.1,-0.1,-0.1,1.0,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,-0.1},{-0.1,-0.1,-0.1,-0.1,1.0,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,-0.1}},{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0}},{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0}},{{-0.1,-0.1,-0.1,-0.1,1.0,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,-0.1},{-0.1,-0.1,-0.1,-0.1,1.0,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,-0.1},{-0.1,-0.1,-0.1,-0.1,1.0,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,-0.1},{-0.1,-0.1,-0.1,-0.1,1.0,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,-0.1}},{{-0.1,-0.1,-0.1,-0.1,1.0,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,-0.1},{-0.1,-0.1,-0.1,-0.1,1.0,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,-0.1},{-0.1,-0.1,-0.1,-0.1,1.0,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,-0.1},{-0.1,-0.1,-0.1,-0.1,1.0,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,-0.1}},{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0}}};;
		double gamma = 0.99;*/
		
		
		//Original function
		/*int numStates = 9;

		int numActions = 4;

		double[][][] probabilitiesOfTransitions = {{{1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0}},{{0.0,0.1,0.8,0.0,0.1,0.0,0.0,0.0,0.0},{0.0,0.9,0.1,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.9,0.0,0.0,0.1,0.0,0.0,0.0,0.0},{0.0,0.1,0.1,0.0,0.8,0.0,0.0,0.0,0.0}},{{0.0,0.0,0.9,0.0,0.0,0.1,0.0,0.0,0.0},{0.0,0.1,0.9,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.8,0.1,0.0,0.0,0.1,0.0,0.0,0.0},{0.0,0.1,0.1,0.0,0.0,0.8,0.0,0.0,0.0}},{{0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0}},{{0.0,0.1,0.0,0.0,0.0,0.8,0.0,0.1,0.0},{0.0,0.8,0.0,0.1,0.0,0.1,0.0,0.0,0.0},{0.0,0.1,0.0,0.8,0.0,0.0,0.0,0.1,0.0},{0.0,0.0,0.0,0.1,0.0,0.1,0.0,0.8,0.0}},{{0.0,0.0,0.1,0.0,0.0,0.8,0.0,0.0,0.1},{0.0,0.0,0.8,0.0,0.1,0.1,0.0,0.0,0.0},{0.0,0.0,0.1,0.0,0.8,0.0,0.0,0.0,0.1},{0.0,0.0,0.0,0.0,0.1,0.1,0.0,0.0,0.8}},{{0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0}},{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0}},{{0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.9},{0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.1,0.1},{0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.8,0.1},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.9}}};

		double[][][] rewards = {{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0}},{{-0.1,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,1.0,-0.1},{-0.1,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,1.0,-0.1},{-0.1,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,1.0,-0.1},{-0.1,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,1.0,-0.1}},{{-0.1,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,1.0,-0.1},{-0.1,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,1.0,-0.1},{-0.1,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,1.0,-0.1},{-0.1,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,1.0,-0.1}},{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0}},{{-0.1,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,1.0,-0.1},{-0.1,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,1.0,-0.1},{-0.1,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,1.0,-0.1},{-0.1,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,1.0,-0.1}},{{-0.1,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,1.0,-0.1},{-0.1,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,1.0,-0.1},{-0.1,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,1.0,-0.1},{-0.1,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,1.0,-0.1}},{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0}},{{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0},{0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0}},{{-0.1,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,1.0,-0.1},{-0.1,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,1.0,-0.1},{-0.1,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,1.0,-0.1},{-0.1,-0.1,-0.1,-1.0,-0.1,-0.1,-0.1,1.0,-0.1}}};

		double gamma = 0.999;*/

		
		
		RewardShapingHW5TestEg1 obj = new RewardShapingHW5TestEg1(probabilitiesOfTransitions,rewards,
				gamma,numStates,numActions);
		//obj.FuncValue();
		obj.setRewardFun(rewards, gamma,numStates,probabilitiesOfTransitions);
		
		System.out.println("Policy iterations with original reward function ");
		
		obj.PolicyIterationRFSimple(gamma);
		
		System.out.println();
		System.out.println();
		
		System.out.println("Policy iterations with new reward function ");
		
		obj.PolicyIterationRFModified(gamma);

		
		
		
		
		//mdp.computeValue(gamma);
		//System.out.println("Best initial action: " + mdp.bestFirstAction(gamma));
		//obj.PolicyIterationExample(gamma);
		
	}
}


